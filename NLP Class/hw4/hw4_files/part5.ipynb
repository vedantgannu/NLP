{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20165,"status":"ok","timestamp":1669607670089,"user":{"displayName":"Vedant Gannu","userId":"02485315243456304443"},"user_tz":300},"id":"aKObZkY3gJme","outputId":"a0a00331-26e9-4bd9-a9b7-62a1a958fe92"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n","Requirement already satisfied: regex\u003e=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (4.2.0)\n","Requirement already satisfied: numpy\u003e=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n","Requirement already satisfied: scipy\u003e=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.7.3)\n","Requirement already satisfied: smart-open\u003e=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: tokenizers!=0.11.3,\u003c0.14,\u003e=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.10.0-\u003etransformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers) (3.0.9)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers) (3.10.0)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (3.0.4)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (1.24.3)\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"name":"stdout","output_type":"stream","text":["/content/gdrive/MyDrive/Colab Notebooks/NLP/hw4_files\n","gold.trial                             lexsub_trial.xml  \u001b[0m\u001b[01;34m__pycache__\u001b[0m/\n","GoogleNews-vectors-negative300.bin.gz  lexsub_xml.py     score.pl\n","lexsub_main.py                         part5.ipynb       smurf.predict\n","/content/gdrive/MyDrive/Colab Notebooks/NLP/hw4_files\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","import os\n","\n","!pip install --upgrade nltk\n","!pip install --upgrade gensim\n","!pip install --upgrade transformers\n","\n","import nltk\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","nltk.download('stopwords')\n","\n","%cd \"/content/gdrive/MyDrive/Colab Notebooks/NLP/hw4_files\"\n","%ls\n","print(os.path.abspath(\".\"))\n","root = os.path.abspath(\".\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36936,"status":"ok","timestamp":1669157515437,"user":{"displayName":"Vedant Gannu","userId":"02485315243456304443"},"user_tz":300},"id":"xuLmqpdoT81Y","outputId":"dd5aa6f1-6c18-4436-fb03-d2b7d26488bd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/u/1/uc?id=1iXg_kgfutb9pJwDAEizS8ZT6jcYSpCjy\n","To: /content/gdrive/MyDrive/Colab Notebooks/NLP/hw4_files/GoogleNews-vectors-negative300.bin.gz\n","100% 1.65G/1.65G [00:35\u003c00:00, 46.4MB/s]\n"]}],"source":["#!gdown https://drive.google.com/u/1/uc?id=1iXg_kgfutb9pJwDAEizS8ZT6jcYSpCjy\u0026export=download"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":478,"status":"ok","timestamp":1669607351452,"user":{"displayName":"Vedant Gannu","userId":"02485315243456304443"},"user_tz":300},"id":"HIrIwrss2RPm","outputId":"95c64816-e9f8-4ad1-8822-a48c2815a256"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":168,"status":"ok","timestamp":1669504577610,"user":{"displayName":"Vedant Gannu","userId":"02485315243456304443"},"user_tz":300},"id":"ZDDaaE1g131b","outputId":"43ea7ade-fade-47b7-b7c6-e56647ff6dc7"},"outputs":[{"data":{"text/plain":["[Lemma('interruption.n.02.break'),\n"," Lemma('break.n.02.break'),\n"," Lemma('fault.n.04.break'),\n"," Lemma('rupture.n.02.break'),\n"," Lemma('respite.n.02.break'),\n"," Lemma('breakage.n.03.break'),\n"," Lemma('pause.n.01.break'),\n"," Lemma('fracture.n.01.break'),\n"," Lemma('break.n.09.break'),\n"," Lemma('break.n.10.break'),\n"," Lemma('break.n.11.break'),\n"," Lemma('break.n.12.break'),\n"," Lemma('break.n.13.break'),\n"," Lemma('break.n.14.break'),\n"," Lemma('open_frame.n.01.break'),\n"," Lemma('break.n.16.break')]"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["from nltk.corpus import wordnet as wn\n","wn.lemmas('break', pos='n') # Retrieve all lexemes for the noun 'break'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TVbEV3RO2bxd"},"outputs":[],"source":["l1 = wn.lemmas('break', pos='n')[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":186,"status":"ok","timestamp":1669504584301,"user":{"displayName":"Vedant Gannu","userId":"02485315243456304443"},"user_tz":300},"id":"LF7aEqyN2ukU","outputId":"a96820ba-759d-4f35-f40c-9b0c8f3e627d"},"outputs":[{"data":{"text/plain":["Synset('interruption.n.02')"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["s1 = l1.synset() # get the synset for the first lexeme\n","s1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":222,"status":"ok","timestamp":1669504585193,"user":{"displayName":"Vedant Gannu","userId":"02485315243456304443"},"user_tz":300},"id":"dbtvm33f2w2j","outputId":"656ebf77-5d70-466d-9a2e-baf2aa73d62b"},"outputs":[{"data":{"text/plain":["[Lemma('interruption.n.02.interruption'), Lemma('interruption.n.02.break')]"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["s1.lemmas() # Get all lexemes in that synset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":216,"status":"ok","timestamp":1669504587713,"user":{"displayName":"Vedant Gannu","userId":"02485315243456304443"},"user_tz":300},"id":"ZzBwxL6r24Jv","outputId":"fbb2cd22-68cf-4788-c5f0-5ec790490083"},"outputs":[{"name":"stdout","output_type":"stream","text":["['interruption', 'break']\n"]}],"source":["#s1.lemmas()[0].name()\n","print([thing.name() for thing in s1.lemmas()])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":300,"status":"ok","timestamp":1669162978806,"user":{"displayName":"Vedant Gannu","userId":"02485315243456304443"},"user_tz":300},"id":"tXb8aR9B28oc","outputId":"8e52a874-bc4f-4b3d-b8e8-b05fec2af959"},"outputs":[{"data":{"text/plain":["['the telephone is an annoying interruption',\n"," 'there was a break in the action when a player was hurt']"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["s1.examples()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":145,"status":"ok","timestamp":1669164110079,"user":{"displayName":"Vedant Gannu","userId":"02485315243456304443"},"user_tz":300},"id":"LKj-If_U3cvc","outputId":"6cd3d3b5-48c8-42e7-903f-96d5421ae485"},"outputs":[{"data":{"text/plain":["[Synset('happening.n.01')]"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["s1.hypernyms()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":172,"status":"ok","timestamp":1669164094172,"user":{"displayName":"Vedant Gannu","userId":"02485315243456304443"},"user_tz":300},"id":"sD_ZTPX23hW8","outputId":"672ba8c8-ea84-458c-93f4-2822ea0a9aff"},"outputs":[{"data":{"text/plain":["[Synset('dislocation.n.01'),\n"," Synset('eclipse.n.01'),\n"," Synset('punctuation.n.01'),\n"," Synset('suspension.n.04')]"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["s1.hyponyms()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":195,"status":"ok","timestamp":1669504593372,"user":{"displayName":"Vedant Gannu","userId":"02485315243456304443"},"user_tz":300},"id":"DfkrzD7h7tFT","outputId":"9054306d-1886-44d4-9967-d1a5458e9bdc"},"outputs":[{"data":{"text/plain":["3"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["l1.count()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XMmxiCzj71es"},"outputs":[],"source":["import gensim\n","model = gensim.models.KeyedVectors.load_word2vec_format('/content/gdrive/MyDrive/Colab Notebooks/NLP/hw4_files/GoogleNews-vectors-negative300.bin.gz', binary=True) "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":328},"executionInfo":{"elapsed":159,"status":"error","timestamp":1669531721414,"user":{"displayName":"Vedant Gannu","userId":"02485315243456304443"},"user_tz":300},"id":"bbIWteUk75Xc","outputId":"2bba1348-63c1-4e69-b1d2-6c2630caea1d"},"outputs":[{"ename":"KeyError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-23-857e14f9f158\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#v1 = model.wv['computer']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"picture_show\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \"\"\"\n\u001b[0;32m--\u003e 447\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 421\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"Key 'picture_show' not present\""]}],"source":["#v1 = model.wv['computer']\n","model.get_vector(\"picture_show\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3152,"status":"ok","timestamp":1669606418975,"user":{"displayName":"Vedant Gannu","userId":"02485315243456304443"},"user_tz":300},"id":"88AQE5XK8llm","outputId":"4c8a562f-f9a6-4617-bb93-fb522c15591c"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForMaskedLM: ['activation_13']\n","- This IS expected if you are initializing TFDistilBertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFDistilBertForMaskedLM were initialized from the model checkpoint at distilbert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForMaskedLM for predictions without further training.\n"]}],"source":["import transformers \n","import tensorflow as tf\n","import numpy as np\n","model = transformers.TFDistilBertForMaskedLM.from_pretrained('distilbert-base-uncased')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":373,"status":"ok","timestamp":1669606424832,"user":{"displayName":"Vedant Gannu","userId":"02485315243456304443"},"user_tz":300},"id":"2e1E_aUtCUrJ","outputId":"ff121fdf-f0a9-4d41-9e3b-25564f83f0cf"},"outputs":[{"data":{"text/plain":["['if',\n"," 'your',\n"," 'money',\n"," 'is',\n"," 'tight',\n"," ',',\n"," 'don',\n"," \"'\",\n"," 't',\n"," 'cut',\n"," 'corners',\n"," '.']"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","tokenizer.tokenize(\"If your money is tight, don't cut corners.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CAfg05_GEhMa"},"outputs":[],"source":["input_toks = tokenizer.encode(\"If your money is tight, don't cut corners\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":142,"status":"ok","timestamp":1669606430651,"user":{"displayName":"Vedant Gannu","userId":"02485315243456304443"},"user_tz":300},"id":"ICiLDtPrEl1N","outputId":"a6b4c8f3-fb4c-4b1f-c68e-b9c697b8851f"},"outputs":[{"data":{"text/plain":["[101, 2065, 2115, 2769, 2003, 4389, 1010, 2123, 1005, 1056, 3013, 8413, 102]"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["input_toks"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":212,"status":"ok","timestamp":1669606227210,"user":{"displayName":"Vedant Gannu","userId":"02485315243456304443"},"user_tz":300},"id":"VYAQ2rTpEmlK","outputId":"c6177d23-100b-4957-db28-5c616a626958"},"outputs":[{"data":{"text/plain":["['[CLS]',\n"," 'if',\n"," 'your',\n"," 'money',\n"," 'is',\n"," 'tight',\n"," ',',\n"," 'don',\n"," \"'\",\n"," 't',\n"," 'cut',\n"," 'corners',\n"," '[SEP]']"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.convert_ids_to_tokens(input_toks)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":542,"status":"ok","timestamp":1669606454016,"user":{"displayName":"Vedant Gannu","userId":"02485315243456304443"},"user_tz":300},"id":"xOiVS0tvEpMk","outputId":"0a6527f0-ac90-42c5-b088-bb616e50ed3f"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 304ms/step\n"]}],"source":["input_mat = np.array(input_toks).reshape((1,-1))  # get a 1 x len(input_toks) matrix\n","outputs = model.predict(input_mat)\n","predictions = outputs[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":144,"status":"ok","timestamp":1669606457736,"user":{"displayName":"Vedant Gannu","userId":"02485315243456304443"},"user_tz":300},"id":"1s2_e0xQFC_Z","outputId":"96fb539c-7edb-442f-888a-269a8399f64e"},"outputs":[{"data":{"text/plain":["(1, 13, 30522)"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["outputs.logits.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":146,"status":"ok","timestamp":1669606459519,"user":{"displayName":"Vedant Gannu","userId":"02485315243456304443"},"user_tz":300},"id":"AaGxuSpDFP3U","outputId":"da1fdc27-f32e-41ad-a8de-77e78b18049c"},"outputs":[{"data":{"text/plain":["array([-9.633242, -9.816507, -9.480414, ..., -8.620842, -6.931805,\n","       -4.441959], dtype=float32)"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["predictions[0,5]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1669606461776,"user":{"displayName":"Vedant Gannu","userId":"02485315243456304443"},"user_tz":300},"id":"KD9RBIAXGSZ0","outputId":"a579ddf3-9708-47f8-fec1-a4dfe9a192e7"},"outputs":[{"data":{"text/plain":["array([ 4389,  2485,  6065, ..., 25084, 12112, 24546])"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["best_words = np.argsort(predictions[0][5])[::-1] # Sort in increasing order\n","best_words"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":141,"status":"ok","timestamp":1669606465142,"user":{"displayName":"Vedant Gannu","userId":"02485315243456304443"},"user_tz":300},"id":"3ShuOOS_HSXF","outputId":"763d9b0e-6f63-4f24-99e9-5ae4452b752e"},"outputs":[{"data":{"text/plain":["['tight',\n"," 'close',\n"," 'loose',\n"," 'deep',\n"," 'big',\n"," 'tighter',\n"," 'tied',\n"," 'firm',\n"," 'hard',\n"," 'down']"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.convert_ids_to_tokens(best_words[:10])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4YyfLbIyIBiw"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15554,"status":"ok","timestamp":1669607848484,"user":{"displayName":"Vedant Gannu","userId":"02485315243456304443"},"user_tz":300},"id":"Kcbwizt9RoRg","outputId":"9ca7dd9c-2575-4bb2-c075-9e4e0f485f56"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForMaskedLM: ['activation_13']\n","- This IS expected if you are initializing TFDistilBertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFDistilBertForMaskedLM were initialized from the model checkpoint at distilbert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForMaskedLM for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 7s 7s/step\n"]},{"data":{"text/plain":["['stolen',\n"," 'wasted',\n"," 'worthless',\n"," 'dirty',\n"," 'yours',\n"," 'lost',\n"," 'money',\n"," 'worth',\n"," 'good',\n"," 'bad']"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["import transformers \n","import tensorflow as tf\n","import numpy as np\n","model = transformers.TFDistilBertForMaskedLM.from_pretrained('distilbert-base-uncased')\n","\n","tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","input_toks = tokenizer.encode(\"If your money is [MASK], don't cut corners\")\n","input_mat = np.array(input_toks).reshape((1,-1))\n","outputs = model.predict(input_mat)\n","predictions = outputs[0]\n","best_words = np.argsort(predictions[0][5])[::-1] # Sort in increasing order\n","tokenizer.convert_ids_to_tokens(best_words[:10])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":183,"status":"ok","timestamp":1669608654255,"user":{"displayName":"Vedant Gannu","userId":"02485315243456304443"},"user_tz":300},"id":"IMeah_m6RrEs","outputId":"10f20d81-4b32-4ff3-db8b-80609341c606"},"outputs":[{"data":{"text/plain":["[101, 2065, 2115, 2769, 2003, 103, 1010, 2123, 1005, 1056, 3013, 8413, 102]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["input_toks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"40zNCg_NUvek"},"outputs":[],"source":["from collections import defaultdict\n","import sys\n","\n","from lexsub_xml import read_lexsub_xml\n","from lexsub_xml import Context \n","\n","# suggested imports \n","from nltk.corpus import wordnet as wn\n","from nltk.corpus import stopwords\n","\n","import numpy as np\n","import tensorflow\n","\n","import gensim\n","import transformers \n","\n","from typing import List\n","import string\n","\n","def tokenize(s): \n","    \"\"\"\n","    a naive tokenizer that splits on punctuation and whitespaces.  \n","    \"\"\"\n","    s = \"\".join(\" \" if x in string.punctuation else x for x in s.lower())    \n","    return s.split() \n","\n","def get_candidates(lemma, pos) -\u003e List[str]:\n","    # Part 1\n","    ret = set()\n","    for synset in wn.synsets(lemma, pos=pos):\n","        for lexeme in synset.lemmas():\n","            if lexeme.name() == lemma:\n","                continue\n","            elif lexeme.name().find(\"_\") != -1:\n","                ret.add(lexeme.name().replace(\"_\", \" \"))\n","            else:\n","                ret.add(lexeme.name())\n","    return list(ret)\n","\n","def smurf_predictor(context : Context) -\u003e str:\n","    \"\"\"\n","    suggest 'smurf' as a substitute for all words.\n","    \"\"\"\n","    return 'smurf'\n","\n","def wn_frequency_predictor(context : Context): #-\u003e str:\n","    \n","    #return None # replace for part 2\n","    #Context obj: self.cid, self.word_form, self.lemma, self.pos, self.left_context, self.right_context\n","    synsets = wn.synsets(context.lemma, pos=context.pos)#Get the synonym set that the input word relates to\n","    frequency = defaultdict(int)\n","    for synset in synsets:\n","        for lexeme in synset.lemmas():\n","            if lexeme.name() != context.lemma:#Consider the lemmas that aren't the input lemma (synonyms)\n","                frequency[lexeme.name()] += lexeme.count()#Record the number of occurences for each synonym sharing word sense with input lemma\n","                \n","    return max(frequency, key=frequency.get).replace(\"_\", \" \")\n","        \n","        \n","        \n","\n","def wn_simple_lesk_predictor(context : Context) -\u003e str:\n","    synsets = wn.synsets(context.lemma, pos=context.pos)#Get the synonym set that the input word relates to\n","    stop_words = stopwords.words('english')\n","    max_overlap = 0\n","    overlap_dict = defaultdict(int)\n","    for synset in synsets:\n","        #Tokenize and filter out stop words of synset definition, left context, right context, and examples\n","        definitions = [ [word.lower() for word in tokenize(synset.definition()) if word.lower() not in stop_words] ]\n","        left_context = tokenize(\" \".join([word.lower() for word in context.left_context if word.lower() not in stop_words]))\n","        right_context = tokenize(\" \".join([word.lower() for word in context.right_context if word.lower() not in stop_words]))\n","        examples = []\n","        for example in synset.examples():\n","            examples.append([word.lower() for word in tokenize(example) if word.lower() not in stop_words])\n","        #Do same filtering and tokenization for hypernym definitions and examples\n","        for synset_hyper in synset.hypernyms():\n","            definitions.append( [word.lower() for word in tokenize(synset_hyper.definition()) if word.lower() not in stop_words] )\n","            for example in synset_hyper.examples():\n","                examples.append([word.lower() for word in tokenize(example) if word.lower() not in stop_words])\n","        #Get the overlap\n","        overlap = 0\n","        for gloss in definitions + examples:\n","            overlap += len(set(gloss) \u0026 set(left_context)) + len(set(gloss) \u0026 set(right_context))\n","        # if overlap \u003e 0:\n","        #     overlap_dict[synset] = overlap\n","        if overlap \u003e max_overlap:\n","            max_overlap = overlap\n","    best_synsets = [synset for (synset, overlap) in overlap_dict.items() if overlap == max_overlap]\n","    lexemes = []\n","    for synset in (best_synsets if best_synsets else synsets):\n","        #print(synset.lemmas())\n","        for lexeme in synset.lemmas():\n","            if lexeme.name() != context.lemma:\n","                lexemes.append(lexeme)\n","    if lexemes:\n","        return max(lexemes, key=lambda x: x.count()).name().replace(\"_\", \" \")\n","    else:\n","        return \"smurf\"\n","                \n","            \n","    #return None #replace for part 3\n","   \n","\n","class Word2VecSubst(object):\n","        \n","    def __init__(self, filename):\n","        self.model = gensim.models.KeyedVectors.load_word2vec_format(filename, binary=True)    \n","\n","    def predict_nearest(self,context : Context) -\u003e str:\n","        syns = get_candidates(context.lemma, context.pos)\n","        lemmas = []\n","        for syn in syns:\n","            try:\n","                lemmas.append((syn, self.model.similarity(context.lemma, syn.replace(\" \",  \"_\"))))\n","            except:\n","                continue\n","        if lemmas:\n","             return max(lemmas, key=lambda lemma: lemma[1])[0]\n","        else:\n","            return \"smurf\"\n","        #return None # replace for part 4\n","\n","\n","class BertPredictor(object):\n","\n","    def __init__(self): \n","        self.tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","        self.model = transformers.TFDistilBertForMaskedLM.from_pretrained('distilbert-base-uncased')\n","\n","    def predict(self, context : Context) -\u003e str:\n","      syns = get_candidates(context.lemma, context.pos)\n","      print(\"Syns:\", syns)\n","\n","      input_toks = self.tokenizer.tokenize(\" \".join(context.left_context + [\"[MASK]\"] + context.right_context))\n","      print(\"Input:\", input_toks)\n","      mask_index = input_toks.index(\"[MASK]\")\n","      input_toks_encoded = self.tokenizer.encode(input_toks)\n","      input_mat = np.array(input_toks_encoded).reshape((1,-1))\n","      outputs = self.model.predict(input_mat)\n","      predictions = outputs[0]\n","      best_words_indices = np.argsort(predictions[0][mask_index])[::-1] # Sort in increasing order\n","      best_words = self.tokenizer.convert_ids_to_tokens(best_words_indices)\n","      print(\"Best words:\", best_words)\n","      for word in best_words:\n","        if word in syns:\n","          print(\"Best word:\", word)\n","          return word\n","      return \"smurf\"\n","      #return None # replace for part 5\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gyCQpL30Uycl"},"outputs":[],"source":["with open('smurf.predict', 'w') as f:\n","  for context in read_lexsub_xml(\"lexsub_trial.xml\"):\n","          #print(context)  # useful for debugging\n","          prediction = wn_simple_lesk_predictor(context)\n","          print(\"{}.{} {} :: {}\".format(context.lemma, context.pos, context.cid, prediction), file=f)\n","!perl score.pl smurf.predict gold.trial"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":74664,"status":"ok","timestamp":1669607786895,"user":{"displayName":"Vedant Gannu","userId":"02485315243456304443"},"user_tz":300},"id":"tfpDcsIOWAgp","outputId":"da3c0cc0-9d12-4474-d4bc-ec3f3f779bee"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total = 298, attempted = 298\n","precision = 0.115, recall = 0.115\n","Total with mode 206 attempted 206\n","precision = 0.170, recall = 0.170\n"]}],"source":["with open('smurf.predict', 'w') as f:\n","  W2VMODEL_FILENAME = 'GoogleNews-vectors-negative300.bin.gz'\n","  predictor = Word2VecSubst(W2VMODEL_FILENAME)\n","  for context in read_lexsub_xml(\"lexsub_trial.xml\"):\n","      #print(context)  # useful for debugging\n","      prediction = predictor.predict_nearest(context)\n","      print(\"{}.{} {} :: {}\".format(context.lemma, context.pos, context.cid, prediction), file=f)\n","!perl score.pl smurf.predict gold.trial"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"1IFwijASRLGGgnMApHXtmY6yS26HX8Ba_"},"id":"8sHpRjBPW4Tb","outputId":"0ec1c54b-8e67-44b8-afa3-802db3454da1"},"outputs":[],"source":["with open('smurf.predict', 'w') as f:\n","  predictor = BertPredictor()\n","  for context in read_lexsub_xml(\"lexsub_trial.xml\"):\n","      #print(context)  # useful for debugging\n","      prediction = predictor.predict(context)\n","      print(\"{}.{} {} :: {}\".format(context.lemma, context.pos, context.cid, prediction), file=f)\n","#!perl score.pl smurf.predict gold.trial\n","\n","# for context in read_lexsub_xml(\"lexsub_trial.xml\"):\n","#   print(context.left_context)\n","#   print(context.right_context)\n","#   print(context.left_context + [\"[MASK]\"] + context.right_context)\n","#   print(tokenizer.convert_ids_to_tokens(tokenizer.encode(\" \".join(context.left_context + [\"[MASK]\"] + context.right_context))))\n","#   print()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MFxT1dazgQ-L"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMXR/Pk7m9rGrfO265aTxNY","name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}